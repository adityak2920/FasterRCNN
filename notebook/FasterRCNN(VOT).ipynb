{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsYk3kYfLEU5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "    This notebook is for training FasterRCNN using VOCDataset, for training with other datasets, refer to readme of this repository.\n",
    "    Here I have only used detection parameters of VOCDataset. VOCDataset has 20 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRjJ_PuIeyOF"
   },
   "outputs": [],
   "source": [
    "# Here we have defined 21 classes by considering first class as background and rest as classes of VOCDataset.\n",
    "classes = ['__background__','aeroplane', 'bicycle', 'bird', 'boat','bottle', 'bus', 'car', 'cat', 'chair','cow', 'diningtable', 'dog', 'horse','motorbike', 'person', 'pottedplant','sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "siqatPtvUyOt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import collections\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import xml.etree.cElementTree as ET\n",
    "else:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.datasets.utils import download_url, check_integrity, verify_str_arg\n",
    "\n",
    "# Here we have defined links for downloading different VOCDataset based on year.\n",
    "DATASET_YEAR_DICT = {\n",
    "    '2012': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar',\n",
    "        'filename': 'VOCtrainval_11-May-2012.tar',\n",
    "        'md5': '6cd6e144f989b92b3379bac3b3de84fd',\n",
    "        'base_dir': os.path.join('VOCdevkit', 'VOC2012')\n",
    "    },\n",
    "    '2011': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2011/VOCtrainval_25-May-2011.tar',\n",
    "        'filename': 'VOCtrainval_25-May-2011.tar',\n",
    "        'md5': '6c3384ef61512963050cb5d687e5bf1e',\n",
    "        'base_dir': os.path.join('TrainVal', 'VOCdevkit', 'VOC2011')\n",
    "    },\n",
    "    '2010': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2010/VOCtrainval_03-May-2010.tar',\n",
    "        'filename': 'VOCtrainval_03-May-2010.tar',\n",
    "        'md5': 'da459979d0c395079b5c75ee67908abb',\n",
    "        'base_dir': os.path.join('VOCdevkit', 'VOC2010')\n",
    "    },\n",
    "    '2009': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar',\n",
    "        'filename': 'VOCtrainval_11-May-2009.tar',\n",
    "        'md5': '59065e4b188729180974ef6572f6a212',\n",
    "        'base_dir': os.path.join('VOCdevkit', 'VOC2009')\n",
    "    },\n",
    "    '2008': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2008/VOCtrainval_14-Jul-2008.tar',\n",
    "        'filename': 'VOCtrainval_11-May-2012.tar',\n",
    "        'md5': '2629fa636546599198acfcfbfcf1904a',\n",
    "        'base_dir': os.path.join('VOCdevkit', 'VOC2008')\n",
    "    },\n",
    "    '2007': {\n",
    "        'url': 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar',\n",
    "        'filename': 'VOCtrainval_06-Nov-2007.tar',\n",
    "        'md5': 'c52e279531787c972589f7e41ab4ae64',\n",
    "        'base_dir': os.path.join('VOCdevkit', 'VOC2007')\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Dataset Class\n",
    "class VOCDetection(VisionDataset):\n",
    "    \"\"\"`Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ Detection Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of the VOC Dataset.\n",
    "        year (string, optional): The dataset year, supports years 2007 to 2012.\n",
    "        image_set (string, optional): Select the image_set to use, ``train``, ``trainval`` or ``val``\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "            (default: alphabetic indexing of VOC's 20 classes).\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, required): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
    "            and returns a transformed version.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 year='2012',\n",
    "                 image_set='train',\n",
    "                 download=False,\n",
    "                 transform=None,\n",
    "                 target_transform=None,\n",
    "                 transforms=None):\n",
    "        super(VOCDetection, self).__init__(root, transforms, transform, target_transform)\n",
    "        self.year = year\n",
    "        self.url = DATASET_YEAR_DICT[year]['url']\n",
    "        self.filename = DATASET_YEAR_DICT[year]['filename']\n",
    "        self.md5 = DATASET_YEAR_DICT[year]['md5']\n",
    "        valid_sets = [\"train\", \"trainval\", \"val\"]\n",
    "        if year == \"2007\":\n",
    "            valid_sets.append(\"test\")\n",
    "        self.image_set = verify_str_arg(image_set, \"image_set\", valid_sets)\n",
    "\n",
    "        base_dir = DATASET_YEAR_DICT[year]['base_dir']\n",
    "        voc_root = os.path.join(self.root, base_dir)\n",
    "        image_dir = os.path.join(voc_root, 'JPEGImages')\n",
    "        annotation_dir = os.path.join(voc_root, 'Annotations')\n",
    "\n",
    "        if download:\n",
    "            download_extract(self.url, self.root, self.filename, self.md5)\n",
    "\n",
    "        if not os.path.isdir(voc_root):\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        splits_dir = os.path.join(voc_root, 'ImageSets/Main')\n",
    "\n",
    "        split_f = os.path.join(splits_dir, image_set.rstrip('\\n') + '.txt')\n",
    "\n",
    "        with open(os.path.join(split_f), \"r\") as f:\n",
    "            file_names = [x.strip() for x in f.readlines()]\n",
    "\n",
    "        self.images = [os.path.join(image_dir, x + \".jpg\") for x in file_names]\n",
    "        self.annotations = [os.path.join(annotation_dir, x + \".xml\") for x in file_names]\n",
    "        assert (len(self.images) == len(self.annotations))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is a dictionary of the XML tree.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.images[index]).convert('RGB')\n",
    "        raw_target = self.parse_voc_xml(\n",
    "            ET.parse(self.annotations[index]).getroot())\n",
    "        \n",
    "        target = {}\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        try:\n",
    "            for that in raw_target[\"annotation\"][\"object\"]:\n",
    "                boxes.append(list(map(float, list(that[\"bndbox\"].values()))))\n",
    "                labels.append(classes.index(that[\"name\"]))\n",
    "            target[\"boxes\"] = torch.tensor(boxes)\n",
    "            target[\"labels\"] = torch.tensor(labels)\n",
    "        except TypeError:\n",
    "            boxes.append(list(map(float, list(raw_target[\"annotation\"][\"object\"][\"bndbox\"].values()))))\n",
    "            labels.append(classes.index(raw_target[\"annotation\"][\"object\"][\"name\"]))\n",
    "            target[\"boxes\"] = torch.tensor(boxes)\n",
    "            target[\"labels\"] = torch.tensor(labels)\n",
    "        target[\"image_id\"] = torch.tensor([int(raw_target[\"annotation\"][\"filename\"].split(\".\")[0])])\n",
    "        \n",
    "    \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def parse_voc_xml(self, node):\n",
    "        voc_dict = {}\n",
    "        children = list(node)\n",
    "        if children:\n",
    "            def_dic = collections.defaultdict(list)\n",
    "            for dc in map(self.parse_voc_xml, children):\n",
    "                for ind, v in dc.items():\n",
    "                    def_dic[ind].append(v)\n",
    "            if node.tag == 'annotation':\n",
    "                def_dic['object'] = [def_dic['object']]\n",
    "            voc_dict = {\n",
    "                node.tag:\n",
    "                    {ind: v[0] if len(v) == 1 else v\n",
    "                     for ind, v in def_dic.items()}\n",
    "            }\n",
    "        if node.text:\n",
    "            text = node.text.strip()\n",
    "            if not children:\n",
    "                voc_dict[node.tag] = text\n",
    "        return voc_dict\n",
    "\n",
    "\n",
    "def download_extract(url, root, filename, md5):\n",
    "    download_url(url, root, filename, md5)\n",
    "    with tarfile.open(os.path.join(root, filename), \"r\") as tar:\n",
    "        tar.extractall(path=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D6INbybue0sM",
    "outputId": "c509e686-332f-49cc-80f1-588a8193453a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./VOCtrainval_06-Nov-2007.tar\n"
     ]
    }
   ],
   "source": [
    "# Just calling dataset class to check weather everything is working fine.\n",
    "datadict = VOCDetection(\".\", year=\"2007\", download=True, transforms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSPFCztNU_Zr"
   },
   "outputs": [],
   "source": [
    "# importing useful python scripts for training and utility functions.\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import transforms as T\n",
    "import utils\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "    \n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKeum3syWOLr"
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# data_loader = torch.utils.data.DataLoader(datadict, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "# images,targets = next(iter(data_loader))\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "# output = model(images,targets)   # Returns losses and detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aEelVSgjYN55",
    "outputId": "56ec59e1-61b6-4627-e004-1e3beb1e0fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_classifier': tensor(2.1501, grad_fn=<NllLossBackward>), 'loss_box_reg': tensor(0.4055, grad_fn=<DivBackward0>), 'loss_objectness': tensor(0.0180, grad_fn=<BinaryCrossEntropyWithLogitsBackward>), 'loss_rpn_box_reg': tensor(0.0361, grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQUi-WALOjpy"
   },
   "outputs": [],
   "source": [
    "# # For inference\n",
    "# model.cpu()\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x) \n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_rcnn_model(num_classes, device):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODhOrPGJc-Hn"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# defining functions for training.\n",
    "def main():\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    dataset = VOCDetection(\".\", year=\"2007\", transforms=get_transform(train=True))\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "    dataset_test = torch.utils.data.Subset(dataset, indices[-50:])\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=4, shuffle=True, num_workers=8,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=4, shuffle=False, num_workers=8,\n",
    "        collate_fn=utils.collate_fn)\n",
    "    \n",
    "    \n",
    "    num_classes = 21  #  classes + background \n",
    "    model = faster_rcnn_model(num_classes, device)\n",
    "    \n",
    "    #defining paremeters for training\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                              momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                 step_size=3,\n",
    "                                                 gamma=0.1)\n",
    "\n",
    "    \n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      # train for one epoch, printing every 10 iterations\n",
    "      train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "      # update the learning rate\n",
    "      lr_scheduler.step()\n",
    "      # evaluate on the test dataset\n",
    "      evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(\"That's it!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pH7ZUTg87IA2",
    "outputId": "4f580786-24b4-416e-d252-afaf91407563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/613]  eta: 0:15:39  lr: 0.000013  loss: 2.9484 (2.9484)  loss_classifier: 2.7104 (2.7104)  loss_box_reg: 0.1975 (0.1975)  loss_objectness: 0.0109 (0.0109)  loss_rpn_box_reg: 0.0295 (0.0295)  time: 1.5324  data: 0.6506  max mem: 4603\n",
      "Epoch: [0]  [ 10/613]  eta: 0:07:35  lr: 0.000095  loss: 3.0651 (2.9660)  loss_classifier: 2.7525 (2.6548)  loss_box_reg: 0.2853 (0.2678)  loss_objectness: 0.0156 (0.0166)  loss_rpn_box_reg: 0.0208 (0.0267)  time: 0.7559  data: 0.0652  max mem: 6370\n",
      "Epoch: [0]  [ 20/613]  eta: 0:07:36  lr: 0.000176  loss: 2.3115 (2.3566)  loss_classifier: 2.0950 (2.0694)  loss_box_reg: 0.2212 (0.2441)  loss_objectness: 0.0115 (0.0141)  loss_rpn_box_reg: 0.0238 (0.0291)  time: 0.7308  data: 0.0064  max mem: 7210\n",
      "Epoch: [0]  [ 30/613]  eta: 0:07:24  lr: 0.000258  loss: 0.9785 (1.8460)  loss_classifier: 0.6815 (1.5649)  loss_box_reg: 0.2078 (0.2383)  loss_objectness: 0.0069 (0.0118)  loss_rpn_box_reg: 0.0241 (0.0310)  time: 0.7667  data: 0.0075  max mem: 7210\n",
      "Epoch: [0]  [ 40/613]  eta: 0:07:15  lr: 0.000340  loss: 0.7543 (1.5774)  loss_classifier: 0.4983 (1.3027)  loss_box_reg: 0.2323 (0.2323)  loss_objectness: 0.0063 (0.0114)  loss_rpn_box_reg: 0.0219 (0.0310)  time: 0.7506  data: 0.0093  max mem: 7210\n",
      "Epoch: [0]  [ 50/613]  eta: 0:07:11  lr: 0.000421  loss: 0.7147 (1.4021)  loss_classifier: 0.4692 (1.1338)  loss_box_reg: 0.2196 (0.2276)  loss_objectness: 0.0070 (0.0112)  loss_rpn_box_reg: 0.0232 (0.0295)  time: 0.7713  data: 0.0096  max mem: 7210\n",
      "Epoch: [0]  [ 60/613]  eta: 0:07:04  lr: 0.000503  loss: 0.7147 (1.2826)  loss_classifier: 0.4614 (1.0163)  loss_box_reg: 0.2196 (0.2263)  loss_objectness: 0.0059 (0.0109)  loss_rpn_box_reg: 0.0216 (0.0291)  time: 0.7858  data: 0.0098  max mem: 7210\n",
      "Epoch: [0]  [ 70/613]  eta: 0:06:57  lr: 0.000584  loss: 0.7576 (1.2131)  loss_classifier: 0.4699 (0.9407)  loss_box_reg: 0.2559 (0.2313)  loss_objectness: 0.0080 (0.0110)  loss_rpn_box_reg: 0.0279 (0.0302)  time: 0.7738  data: 0.0097  max mem: 7711\n",
      "Epoch: [0]  [ 80/613]  eta: 0:06:47  lr: 0.000666  loss: 0.7130 (1.1348)  loss_classifier: 0.4161 (0.8667)  loss_box_reg: 0.2372 (0.2270)  loss_objectness: 0.0086 (0.0109)  loss_rpn_box_reg: 0.0258 (0.0302)  time: 0.7506  data: 0.0093  max mem: 7711\n",
      "Epoch: [0]  [ 90/613]  eta: 0:06:41  lr: 0.000748  loss: 0.4958 (1.0673)  loss_classifier: 0.3000 (0.8053)  loss_box_reg: 0.1711 (0.2213)  loss_objectness: 0.0076 (0.0110)  loss_rpn_box_reg: 0.0198 (0.0296)  time: 0.7667  data: 0.0092  max mem: 7711\n",
      "Epoch: [0]  [100/613]  eta: 0:06:30  lr: 0.000829  loss: 0.6089 (1.0393)  loss_classifier: 0.3512 (0.7708)  loss_box_reg: 0.2171 (0.2260)  loss_objectness: 0.0098 (0.0126)  loss_rpn_box_reg: 0.0253 (0.0300)  time: 0.7477  data: 0.0092  max mem: 7711\n",
      "Epoch: [0]  [110/613]  eta: 0:06:20  lr: 0.000911  loss: 0.6618 (1.0067)  loss_classifier: 0.3870 (0.7347)  loss_box_reg: 0.2459 (0.2269)  loss_objectness: 0.0118 (0.0154)  loss_rpn_box_reg: 0.0268 (0.0297)  time: 0.7091  data: 0.0092  max mem: 7711\n",
      "Epoch: [0]  [120/613]  eta: 0:06:12  lr: 0.000993  loss: 0.6618 (0.9855)  loss_classifier: 0.3858 (0.7087)  loss_box_reg: 0.2459 (0.2315)  loss_objectness: 0.0110 (0.0154)  loss_rpn_box_reg: 0.0231 (0.0298)  time: 0.7299  data: 0.0094  max mem: 7711\n",
      "Epoch: [0]  [130/613]  eta: 0:06:04  lr: 0.001074  loss: 0.5798 (0.9527)  loss_classifier: 0.3162 (0.6789)  loss_box_reg: 0.2386 (0.2298)  loss_objectness: 0.0066 (0.0148)  loss_rpn_box_reg: 0.0210 (0.0293)  time: 0.7378  data: 0.0094  max mem: 7711\n",
      "Epoch: [0]  [140/613]  eta: 0:05:57  lr: 0.001156  loss: 0.4679 (0.9296)  loss_classifier: 0.2613 (0.6547)  loss_box_reg: 0.1661 (0.2293)  loss_objectness: 0.0085 (0.0160)  loss_rpn_box_reg: 0.0199 (0.0295)  time: 0.7619  data: 0.0093  max mem: 7711\n",
      "Epoch: [0]  [150/613]  eta: 0:05:50  lr: 0.001237  loss: 0.5566 (0.9070)  loss_classifier: 0.3078 (0.6324)  loss_box_reg: 0.2113 (0.2285)  loss_objectness: 0.0130 (0.0161)  loss_rpn_box_reg: 0.0263 (0.0300)  time: 0.7682  data: 0.0095  max mem: 7711\n",
      "Epoch: [0]  [160/613]  eta: 0:05:43  lr: 0.001319  loss: 0.6035 (0.8901)  loss_classifier: 0.3085 (0.6141)  loss_box_reg: 0.2387 (0.2299)  loss_objectness: 0.0147 (0.0161)  loss_rpn_box_reg: 0.0276 (0.0300)  time: 0.7623  data: 0.0095  max mem: 7711\n",
      "Epoch: [0]  [170/613]  eta: 0:05:36  lr: 0.001401  loss: 0.5430 (0.8679)  loss_classifier: 0.2842 (0.5943)  loss_box_reg: 0.2290 (0.2285)  loss_objectness: 0.0104 (0.0158)  loss_rpn_box_reg: 0.0194 (0.0293)  time: 0.7842  data: 0.0094  max mem: 7711\n",
      "Epoch: [0]  [180/613]  eta: 0:05:28  lr: 0.001482  loss: 0.4256 (0.8494)  loss_classifier: 0.2464 (0.5776)  loss_box_reg: 0.1728 (0.2267)  loss_objectness: 0.0075 (0.0157)  loss_rpn_box_reg: 0.0223 (0.0295)  time: 0.7757  data: 0.0094  max mem: 7711\n",
      "Epoch: [0]  [190/613]  eta: 0:05:20  lr: 0.001564  loss: 0.4374 (0.8308)  loss_classifier: 0.2354 (0.5613)  loss_box_reg: 0.1652 (0.2244)  loss_objectness: 0.0083 (0.0155)  loss_rpn_box_reg: 0.0294 (0.0297)  time: 0.7394  data: 0.0094  max mem: 7711\n",
      "Epoch: [0]  [200/613]  eta: 0:05:12  lr: 0.001646  loss: 0.3725 (0.8126)  loss_classifier: 0.2001 (0.5454)  loss_box_reg: 0.1420 (0.2222)  loss_objectness: 0.0095 (0.0152)  loss_rpn_box_reg: 0.0282 (0.0298)  time: 0.7282  data: 0.0093  max mem: 7711\n",
      "Epoch: [0]  [210/613]  eta: 0:05:04  lr: 0.001727  loss: 0.3424 (0.7921)  loss_classifier: 0.1848 (0.5289)  loss_box_reg: 0.1371 (0.2191)  loss_objectness: 0.0073 (0.0148)  loss_rpn_box_reg: 0.0201 (0.0293)  time: 0.7486  data: 0.0092  max mem: 7711\n",
      "Epoch: [0]  [220/613]  eta: 0:04:58  lr: 0.001809  loss: 0.3565 (0.7800)  loss_classifier: 0.1843 (0.5172)  loss_box_reg: 0.1436 (0.2186)  loss_objectness: 0.0073 (0.0149)  loss_rpn_box_reg: 0.0201 (0.0294)  time: 0.7949  data: 0.0093  max mem: 7711\n",
      "Epoch: [0]  [230/613]  eta: 0:04:50  lr: 0.001890  loss: 0.3610 (0.7629)  loss_classifier: 0.1679 (0.5031)  loss_box_reg: 0.1436 (0.2158)  loss_objectness: 0.0101 (0.0147)  loss_rpn_box_reg: 0.0244 (0.0293)  time: 0.7878  data: 0.0095  max mem: 7711\n",
      "Epoch: [0]  [240/613]  eta: 0:04:42  lr: 0.001972  loss: 0.2963 (0.7453)  loss_classifier: 0.1486 (0.4893)  loss_box_reg: 0.1383 (0.2127)  loss_objectness: 0.0070 (0.0144)  loss_rpn_box_reg: 0.0192 (0.0289)  time: 0.7270  data: 0.0095  max mem: 7711\n",
      "Epoch: [0]  [250/613]  eta: 0:04:35  lr: 0.002054  loss: 0.3820 (0.7340)  loss_classifier: 0.1833 (0.4789)  loss_box_reg: 0.1632 (0.2115)  loss_objectness: 0.0070 (0.0147)  loss_rpn_box_reg: 0.0175 (0.0288)  time: 0.7592  data: 0.0092  max mem: 7711\n",
      "Epoch: [0]  [260/613]  eta: 0:04:28  lr: 0.002135  loss: 0.4534 (0.7233)  loss_classifier: 0.2297 (0.4693)  loss_box_reg: 0.1863 (0.2105)  loss_objectness: 0.0084 (0.0147)  loss_rpn_box_reg: 0.0249 (0.0289)  time: 0.7934  data: 0.0092  max mem: 7898\n",
      "Epoch: [0]  [270/613]  eta: 0:04:19  lr: 0.002217  loss: 0.4154 (0.7112)  loss_classifier: 0.2031 (0.4591)  loss_box_reg: 0.1679 (0.2088)  loss_objectness: 0.0089 (0.0146)  loss_rpn_box_reg: 0.0252 (0.0287)  time: 0.7326  data: 0.0092  max mem: 7898\n",
      "Epoch: [0]  [280/613]  eta: 0:04:11  lr: 0.002298  loss: 0.3304 (0.7007)  loss_classifier: 0.1595 (0.4496)  loss_box_reg: 0.1537 (0.2079)  loss_objectness: 0.0100 (0.0145)  loss_rpn_box_reg: 0.0234 (0.0287)  time: 0.7142  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [290/613]  eta: 0:04:04  lr: 0.002380  loss: 0.4098 (0.6904)  loss_classifier: 0.1929 (0.4409)  loss_box_reg: 0.1754 (0.2062)  loss_objectness: 0.0100 (0.0147)  loss_rpn_box_reg: 0.0234 (0.0286)  time: 0.7330  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [300/613]  eta: 0:03:56  lr: 0.002462  loss: 0.3706 (0.6806)  loss_classifier: 0.1682 (0.4323)  loss_box_reg: 0.1406 (0.2046)  loss_objectness: 0.0116 (0.0146)  loss_rpn_box_reg: 0.0310 (0.0291)  time: 0.7528  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [310/613]  eta: 0:03:49  lr: 0.002543  loss: 0.3531 (0.6695)  loss_classifier: 0.1407 (0.4231)  loss_box_reg: 0.1481 (0.2028)  loss_objectness: 0.0116 (0.0147)  loss_rpn_box_reg: 0.0364 (0.0289)  time: 0.7922  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [320/613]  eta: 0:03:41  lr: 0.002625  loss: 0.3142 (0.6592)  loss_classifier: 0.1415 (0.4149)  loss_box_reg: 0.1374 (0.2009)  loss_objectness: 0.0113 (0.0147)  loss_rpn_box_reg: 0.0205 (0.0287)  time: 0.7665  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [330/613]  eta: 0:03:34  lr: 0.002707  loss: 0.2839 (0.6493)  loss_classifier: 0.1363 (0.4070)  loss_box_reg: 0.1229 (0.1991)  loss_objectness: 0.0094 (0.0146)  loss_rpn_box_reg: 0.0220 (0.0286)  time: 0.7404  data: 0.0095  max mem: 7898\n",
      "Epoch: [0]  [340/613]  eta: 0:03:26  lr: 0.002788  loss: 0.2764 (0.6397)  loss_classifier: 0.1278 (0.3993)  loss_box_reg: 0.1186 (0.1973)  loss_objectness: 0.0072 (0.0147)  loss_rpn_box_reg: 0.0244 (0.0285)  time: 0.7612  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [350/613]  eta: 0:03:18  lr: 0.002870  loss: 0.3203 (0.6308)  loss_classifier: 0.1273 (0.3920)  loss_box_reg: 0.1332 (0.1957)  loss_objectness: 0.0046 (0.0144)  loss_rpn_box_reg: 0.0292 (0.0287)  time: 0.7512  data: 0.0096  max mem: 7898\n",
      "Epoch: [0]  [360/613]  eta: 0:03:11  lr: 0.002951  loss: 0.2801 (0.6206)  loss_classifier: 0.1143 (0.3844)  loss_box_reg: 0.1102 (0.1936)  loss_objectness: 0.0050 (0.0142)  loss_rpn_box_reg: 0.0228 (0.0285)  time: 0.7301  data: 0.0097  max mem: 7898\n",
      "Epoch: [0]  [370/613]  eta: 0:03:03  lr: 0.003033  loss: 0.2293 (0.6109)  loss_classifier: 0.1022 (0.3771)  loss_box_reg: 0.1001 (0.1912)  loss_objectness: 0.0047 (0.0139)  loss_rpn_box_reg: 0.0203 (0.0286)  time: 0.7345  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [380/613]  eta: 0:02:56  lr: 0.003115  loss: 0.2673 (0.6036)  loss_classifier: 0.1121 (0.3708)  loss_box_reg: 0.1016 (0.1896)  loss_objectness: 0.0078 (0.0145)  loss_rpn_box_reg: 0.0251 (0.0287)  time: 0.7516  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [390/613]  eta: 0:02:48  lr: 0.003196  loss: 0.2667 (0.5952)  loss_classifier: 0.1061 (0.3646)  loss_box_reg: 0.0987 (0.1875)  loss_objectness: 0.0080 (0.0143)  loss_rpn_box_reg: 0.0267 (0.0288)  time: 0.7589  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [400/613]  eta: 0:02:41  lr: 0.003278  loss: 0.2261 (0.5872)  loss_classifier: 0.1074 (0.3587)  loss_box_reg: 0.0987 (0.1856)  loss_objectness: 0.0049 (0.0141)  loss_rpn_box_reg: 0.0227 (0.0287)  time: 0.7806  data: 0.0095  max mem: 7898\n",
      "Epoch: [0]  [410/613]  eta: 0:02:33  lr: 0.003359  loss: 0.3250 (0.5829)  loss_classifier: 0.1471 (0.3551)  loss_box_reg: 0.1425 (0.1849)  loss_objectness: 0.0052 (0.0141)  loss_rpn_box_reg: 0.0229 (0.0288)  time: 0.7457  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [420/613]  eta: 0:02:25  lr: 0.003441  loss: 0.3564 (0.5756)  loss_classifier: 0.1526 (0.3497)  loss_box_reg: 0.1066 (0.1831)  loss_objectness: 0.0064 (0.0140)  loss_rpn_box_reg: 0.0247 (0.0288)  time: 0.7161  data: 0.0092  max mem: 7898\n",
      "Epoch: [0]  [430/613]  eta: 0:02:18  lr: 0.003523  loss: 0.2437 (0.5705)  loss_classifier: 0.1116 (0.3458)  loss_box_reg: 0.1046 (0.1819)  loss_objectness: 0.0064 (0.0140)  loss_rpn_box_reg: 0.0246 (0.0288)  time: 0.7510  data: 0.0092  max mem: 7898\n",
      "Epoch: [0]  [440/613]  eta: 0:02:10  lr: 0.003604  loss: 0.3510 (0.5658)  loss_classifier: 0.1552 (0.3418)  loss_box_reg: 0.1419 (0.1813)  loss_objectness: 0.0074 (0.0139)  loss_rpn_box_reg: 0.0246 (0.0287)  time: 0.7588  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [450/613]  eta: 0:02:03  lr: 0.003686  loss: 0.3051 (0.5602)  loss_classifier: 0.1505 (0.3376)  loss_box_reg: 0.1235 (0.1800)  loss_objectness: 0.0103 (0.0139)  loss_rpn_box_reg: 0.0256 (0.0287)  time: 0.7683  data: 0.0092  max mem: 7898\n",
      "Epoch: [0]  [460/613]  eta: 0:01:55  lr: 0.003768  loss: 0.2677 (0.5556)  loss_classifier: 0.1473 (0.3339)  loss_box_reg: 0.0956 (0.1790)  loss_objectness: 0.0082 (0.0139)  loss_rpn_box_reg: 0.0249 (0.0288)  time: 0.7662  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [470/613]  eta: 0:01:47  lr: 0.003849  loss: 0.2597 (0.5497)  loss_classifier: 0.1366 (0.3297)  loss_box_reg: 0.0956 (0.1776)  loss_objectness: 0.0049 (0.0138)  loss_rpn_box_reg: 0.0249 (0.0287)  time: 0.7491  data: 0.0095  max mem: 7898\n",
      "Epoch: [0]  [480/613]  eta: 0:01:40  lr: 0.003931  loss: 0.2555 (0.5443)  loss_classifier: 0.1135 (0.3254)  loss_box_reg: 0.0890 (0.1765)  loss_objectness: 0.0047 (0.0137)  loss_rpn_box_reg: 0.0281 (0.0287)  time: 0.7547  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [490/613]  eta: 0:01:33  lr: 0.004012  loss: 0.2555 (0.5381)  loss_classifier: 0.1134 (0.3212)  loss_box_reg: 0.1026 (0.1749)  loss_objectness: 0.0032 (0.0136)  loss_rpn_box_reg: 0.0243 (0.0285)  time: 0.7990  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [500/613]  eta: 0:01:25  lr: 0.004094  loss: 0.2756 (0.5343)  loss_classifier: 0.1241 (0.3185)  loss_box_reg: 0.0980 (0.1737)  loss_objectness: 0.0045 (0.0135)  loss_rpn_box_reg: 0.0243 (0.0285)  time: 0.7804  data: 0.0095  max mem: 7898\n",
      "Epoch: [0]  [510/613]  eta: 0:01:17  lr: 0.004176  loss: 0.2834 (0.5299)  loss_classifier: 0.1429 (0.3154)  loss_box_reg: 0.0960 (0.1725)  loss_objectness: 0.0072 (0.0135)  loss_rpn_box_reg: 0.0234 (0.0285)  time: 0.7504  data: 0.0095  max mem: 7898\n",
      "Epoch: [0]  [520/613]  eta: 0:01:10  lr: 0.004257  loss: 0.3170 (0.5267)  loss_classifier: 0.1570 (0.3131)  loss_box_reg: 0.1159 (0.1716)  loss_objectness: 0.0072 (0.0135)  loss_rpn_box_reg: 0.0209 (0.0285)  time: 0.7835  data: 0.0094  max mem: 7898\n",
      "Epoch: [0]  [530/613]  eta: 0:01:02  lr: 0.004339  loss: 0.3110 (0.5222)  loss_classifier: 0.1578 (0.3098)  loss_box_reg: 0.1150 (0.1702)  loss_objectness: 0.0088 (0.0136)  loss_rpn_box_reg: 0.0209 (0.0286)  time: 0.7649  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [540/613]  eta: 0:00:55  lr: 0.004421  loss: 0.3059 (0.5190)  loss_classifier: 0.1509 (0.3073)  loss_box_reg: 0.1150 (0.1695)  loss_objectness: 0.0130 (0.0135)  loss_rpn_box_reg: 0.0303 (0.0287)  time: 0.7368  data: 0.0093  max mem: 7898\n",
      "Epoch: [0]  [550/613]  eta: 0:00:47  lr: 0.004502  loss: 0.3207 (0.5158)  loss_classifier: 0.1674 (0.3049)  loss_box_reg: 0.1242 (0.1687)  loss_objectness: 0.0099 (0.0136)  loss_rpn_box_reg: 0.0251 (0.0287)  time: 0.7861  data: 0.0092  max mem: 8452\n",
      "Epoch: [0]  [560/613]  eta: 0:00:40  lr: 0.004584  loss: 0.3223 (0.5126)  loss_classifier: 0.1651 (0.3025)  loss_box_reg: 0.1111 (0.1677)  loss_objectness: 0.0099 (0.0136)  loss_rpn_box_reg: 0.0267 (0.0287)  time: 0.8002  data: 0.0092  max mem: 8452\n",
      "Epoch: [0]  [570/613]  eta: 0:00:32  lr: 0.004665  loss: 0.2908 (0.5091)  loss_classifier: 0.1482 (0.3003)  loss_box_reg: 0.1080 (0.1665)  loss_objectness: 0.0103 (0.0137)  loss_rpn_box_reg: 0.0235 (0.0285)  time: 0.7773  data: 0.0092  max mem: 8452\n",
      "Epoch: [0]  [580/613]  eta: 0:00:25  lr: 0.004747  loss: 0.2901 (0.5061)  loss_classifier: 0.1482 (0.2984)  loss_box_reg: 0.0893 (0.1655)  loss_objectness: 0.0114 (0.0137)  loss_rpn_box_reg: 0.0177 (0.0285)  time: 0.7448  data: 0.0094  max mem: 8452\n",
      "Epoch: [0]  [590/613]  eta: 0:00:17  lr: 0.004829  loss: 0.3640 (0.5047)  loss_classifier: 0.2091 (0.2971)  loss_box_reg: 0.1097 (0.1649)  loss_objectness: 0.0114 (0.0141)  loss_rpn_box_reg: 0.0315 (0.0286)  time: 0.7153  data: 0.0096  max mem: 8452\n",
      "Epoch: [0]  [600/613]  eta: 0:00:09  lr: 0.004910  loss: 0.3271 (0.5013)  loss_classifier: 0.1808 (0.2947)  loss_box_reg: 0.1131 (0.1640)  loss_objectness: 0.0095 (0.0141)  loss_rpn_box_reg: 0.0315 (0.0286)  time: 0.7751  data: 0.0095  max mem: 8452\n",
      "Epoch: [0]  [610/613]  eta: 0:00:02  lr: 0.004992  loss: 0.2841 (0.4976)  loss_classifier: 0.1456 (0.2923)  loss_box_reg: 0.0884 (0.1627)  loss_objectness: 0.0076 (0.0140)  loss_rpn_box_reg: 0.0254 (0.0286)  time: 0.7766  data: 0.0094  max mem: 8452\n",
      "Epoch: [0]  [612/613]  eta: 0:00:00  lr: 0.005000  loss: 0.2841 (0.4978)  loss_classifier: 0.1560 (0.2923)  loss_box_reg: 0.0865 (0.1627)  loss_objectness: 0.0077 (0.0141)  loss_rpn_box_reg: 0.0248 (0.0287)  time: 0.7582  data: 0.0093  max mem: 8452\n",
      "Epoch: [0] Total time: 0:07:44 (0.7577 s / it)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-36209a1ad8ee>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0;31m# evaluate on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"That's it!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/engine.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Test:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0miou_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_iou_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mcoco_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCocoEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/coco_utils.py\u001b[0m in \u001b[0;36mget_coco_api_from_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCocoDetection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_coco_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/coco_utils.py\u001b[0m in \u001b[0;36mconvert_to_coco_api\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mareas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0miscrowd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iscrowd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'masks'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'area'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "sEC_sXJCP5fu",
    "outputId": "87940416-fb0e-438b-95e9-de04f3d9edfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "LqSDWGaDP5AO",
    "outputId": "a4c2fe82-7cca-4ab9-dd35-b7db1bf4a226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  9 20:53:50 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
